{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYXQKZmmb_mx"
      },
      "source": [
        "**Importing the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p86AwLyZb_m3"
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EixmyE2Eb_m3"
      },
      "source": [
        "**Setting the image height and width**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ2WPbkdb_m4"
      },
      "source": [
        "height = 150\n",
        "width  = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo26Qbdab_m4"
      },
      "source": [
        "**Creating a function to preprocess the image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZSmnhjHb_m4"
      },
      "source": [
        "def preprocess_image(path):\n",
        "    img = image.load_img(path, target_size = (height, width))\n",
        "    a = image.img_to_array(img)\n",
        "    a = np.expand_dims(a, axis = 0)\n",
        "    return preprocess_input(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuTuKPspb_m4"
      },
      "source": [
        "**Setting the directories for reading the training and validation set images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3YIQNgyb_m5"
      },
      "source": [
        "train_dir = \"new_train\\\\\"\n",
        "valid_dir = \"new_valid\\\\\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIVRbucZb_m5"
      },
      "source": [
        "**Getting the class values from the training set images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCPo89mb_m5"
      },
      "source": [
        "classes = os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KicxRbrb_m5"
      },
      "source": [
        "**Displaying the class names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXEEfsYgb_m5",
        "outputId": "65fe461c-1f0e-4e33-9ba3-0b13d1660c8e"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpjDNaXCb_m6"
      },
      "source": [
        "**Getting the training image from their path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKf94Of0b_m7"
      },
      "source": [
        "# Get the training data paths\n",
        "\n",
        "train_paths = []\n",
        "for c in classes:\n",
        "    fish_images = [train_dir+c+'\\\\'+item for item in os.listdir(train_dir+c+'\\\\')]\n",
        "    train_paths.extend(fish_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDCWz4_qb_m7"
      },
      "source": [
        "**Displaying the length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY8Zbwu3b_m7",
        "outputId": "0f3a9fb6-12e1-497c-d612-3d0e18f57e36"
      },
      "source": [
        "len(train_paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3019"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZVOvB6b_m7"
      },
      "source": [
        "**Getting the validation images from their path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvBCfY0sb_m7"
      },
      "source": [
        "valid_paths = []\n",
        "for c in classes:\n",
        "    fish_images = [valid_dir+c+'\\\\'+item for item in os.listdir(valid_dir+c+'\\\\')]\n",
        "    valid_paths.extend(fish_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgfiV9zhb_m7"
      },
      "source": [
        "**Displaying the length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqwCMHvlb_m8",
        "outputId": "9768d722-eb08-42ed-a974-be107978fac7"
      },
      "source": [
        "len(valid_paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886dNp0tb_m8"
      },
      "source": [
        "**Preprcoessing the training images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Khc5xr3b_m8",
        "outputId": "18eab828-f456-4620-e68e-f46cd3cd2f33"
      },
      "source": [
        "%%time\n",
        "preprocessed_images = np.vstack([preprocess_image(fn) for fn in train_paths])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 1min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE2aGcuWb_m8"
      },
      "source": [
        "**Saving the preprocess image as a npy file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmDMH-f7b_m8",
        "outputId": "65c866b3-5717-4b1d-8b71-a2cc75a2466b"
      },
      "source": [
        "%%time\n",
        "np.save(\"train_preprocesed.npy\",preprocessed_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 9.28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Uiof7fb_m9"
      },
      "source": [
        "**Preprocessing the validation set images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euqi0tbsb_m9",
        "outputId": "8c07f507-d45f-4bd0-98f6-68bf402139d4"
      },
      "source": [
        "%%time\n",
        "valid_preprocessed_images = np.vstack(preprocess_image(fn) for fn in valid_paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<timed exec>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 23 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QahxE2tzb_m9"
      },
      "source": [
        "**Saving the preprocessed images as a npy file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS4R0TYfb_m9",
        "outputId": "6eebd0b5-621f-4ab1-fe99-68ddd5265440"
      },
      "source": [
        "%%time\n",
        "np.save(\"valid_preprocessed.npy\",valid_preprocessed_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 2.22 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv1tB0_Wb_m9"
      },
      "source": [
        "**Downloading the VGG16 model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIOUohi5b_m9",
        "outputId": "0cba372a-e2dc-4fd2-80b3-c0a711ec5bc5"
      },
      "source": [
        "model = VGG16(weights=\"imagenet\",include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 81s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox25szMVb_m-"
      },
      "source": [
        "**Loading the npy file for valid images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paGAgm8Db_m-"
      },
      "source": [
        "valid_images = np.load('valid_preprocessed.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-he9rpub_m-",
        "outputId": "8f6318a2-b03b-428f-c7e7-1ee35e79593c"
      },
      "source": [
        "len(valid_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "758"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kafkMB7Tb_m-"
      },
      "source": [
        "**Loading the npy file for training images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uMwlXDxb_m-"
      },
      "source": [
        "train_images = np.load('train_preprocesed.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqfXNUwmb_m_"
      },
      "source": [
        "**Predicting the training set features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjkqCNW4b_m_",
        "outputId": "ce83f98c-2e81-4000-c98d-649b2e17928a"
      },
      "source": [
        "train_features = model.predict(train_images,batch_size = 1,verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3019/3019 [==============================] - 450s 149ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-9tdrdob_m_"
      },
      "source": [
        "**Saving those training set features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNuNFydVb_m_"
      },
      "source": [
        "np.save(\"train_features.npy\",train_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9f6s8H-b_m_"
      },
      "source": [
        "import numpy as np\n",
        "from keras.applications import VGG16\n",
        "model = VGG16(weights=\"imagenet\",include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbk6AZqkb_nA"
      },
      "source": [
        "**Predicting the validation image set features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kvc4zdGb_nA",
        "outputId": "99da8285-0f48-4a8c-c810-58fd40c76c96"
      },
      "source": [
        "valid_features = model.predict(valid_images,batch_size=1,verbose=1)\n",
        "np.save(\"valid_features.npy\",valid_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "758/758 [==============================] - 88s 116ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "718cb2Eeb_nA"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5GSg3Acb_nA"
      },
      "source": [
        "height = 150\n",
        "width  = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Vsq-sRb_nA"
      },
      "source": [
        "def preprocess_image(path):\n",
        "    img = image.load_img(path, target_size = (height, width))\n",
        "    a = image.img_to_array(img)\n",
        "    a = np.expand_dims(a, axis = 0)\n",
        "    return preprocess_input(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9SeUd6Ab_nA"
      },
      "source": [
        "**Getting the test set images from their path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uggQqD2Mb_nB"
      },
      "source": [
        "test_path = [\"test_stg1\\\\test_stg1\\\\\"+name for name in os.listdir(\"test_stg1\\\\test_stg1\\\\\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1iZhBuUb_nB"
      },
      "source": [
        "**Preprocessing the test set images and storing it as a npy file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUG36AXhb_nB",
        "outputId": "e7393a6a-da8a-4cad-9b88-747b5c1c86d8"
      },
      "source": [
        "print(\"preprocessing images\")\n",
        "test_preprocessed_images = np.vstack(preprocess_image(fn) for fn in test_path)\n",
        "np.save(\"test_preprocessed.npy\",test_preprocessed_images)\n",
        "print(\"preprocessing done and saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-30-1ba4a8f90486>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  test_preprocessed_images = np.vstack(preprocess_image(fn) for fn in test_path)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing done and saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meHe52mNb_nB"
      },
      "source": [
        "**Predicting the test set features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqJHTBeQb_nB",
        "outputId": "ee56d985-a138-4729-d380-930fee15ffb3"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "model = VGG16(weights=\"imagenet\",include_top=False)\n",
        "test_features = model.predict(test_preprocessed_images,batch_size=1,verbose=1)\n",
        "np.save(\"test_features.npy\",test_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 115s 115ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypJo7kQb_nB"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "* In this notebook, we make use of the VGG16 model to extract the features for training, test and validation set of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql7CPGUgb_nC"
      },
      "source": [
        "**License**\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 [Prasham Shah, Priyanka Bandekar]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fMul3H6b_nC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}